{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22860f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install selenium using command \" pip install selenium \"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Update the URL of Naukri Page! ( Make Sure that the page link which you're putting must be a job listing page and it must have Next page buttons. )\n",
    "driver.get(\"https://www.google.com/search?q=site%3Alinkedin.com%2Fin+AND+%22Torrent+Pharmaceuticals%22+AND+%28%22Talent+Acquisition%22+OR+%22Human+Resource%22%29&rlz=1C1GCEA_enIN1021IN1021&sxsrf=AB5stBiuPIMXcMPm-tLUpgU369sH8qRgfw%3A1688460472664&ei=uNyjZLWZKOK4seMPl5-AmAc&ved=0ahUKEwi11cK11fT_AhViXGwGHZcPAHMQ4dUDCA8&uact=5&oq=site%3Alinkedin.com%2Fin+AND+%22Torrent+Pharmaceuticals%22+AND+%28%22Talent+Acquisition%22+OR+%22Human+Resource%22%29&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAFAAWABgAGgAcAB4AIABAIgBAJIBAJgBAKABAQ&sclient=gws-wiz-serp\")\n",
    "\n",
    "count = 5  # Update the Number of Vacancy count you want to scrape.\n",
    "\n",
    "index, new_index, i = '0', 1, 0  # This the the index variable of the elements from which data will be Scraped\n",
    "# Xpaths of the various element from which data will be scraped.\n",
    "heading_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/div/div/div/a'\n",
    "#link_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/div/a'\n",
    "#subheading_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/div/div/a'\n",
    "#experience_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/ul/li/span'\n",
    "#salary_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/ul/li[2]/span'\n",
    "#location_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/ul/li[3]/span'\n",
    "\n",
    "csv_file = open('linkedIn2.csv', 'a', encoding=\"utf-8\", newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "# Writing the Heading of CSV file.\n",
    "csv_writer.writerow(['Title', 'Company', 'URL', 'Experience Needed', 'Salary', 'Locations'])\n",
    "\n",
    "while i < count:\n",
    "\n",
    "    for j in range(20):\n",
    "        # Here we're replacing the Old index count of Xpath with New Index count.\n",
    "        temp_index = str(new_index).zfill(2)  # Zfill(2) is used to put zeros to the left of any digit till 2 decimal places.\n",
    "        heading_xpath = heading_xpath.replace(index, temp_index)\n",
    "       # link_xpath = link_xpath.replace(index, temp_index)\n",
    "        #subheading_xpath = subheading_xpath.replace(index, temp_index)\n",
    "        #experience_xpath = experience_xpath.replace(index, temp_index)\n",
    "        #salary_xpath = salary_xpath.replace(index, temp_index)\n",
    "        #location_xpath = location_xpath.replace(index, temp_index)\n",
    "        index = str(new_index).zfill(2)\n",
    "        try:\n",
    "            # Capturing the Heading from webpage and storing that into Heading variable.\n",
    "            heading = wait.until(EC.presence_of_element_located((By.XPATH, heading_xpath))).text\n",
    "            print(heading)\n",
    "        except:\n",
    "            heading = \"NULL\"\n",
    "        new_index += 1\n",
    "        i += 1\n",
    "        print(\"--------------------------- \"+str(i)+\" ----------------------------------\")\n",
    "    ''' try:\n",
    "            link = wait.until(EC.presence_of_element_located((By.XPATH, link_xpath))).get_attribute('href')\n",
    "            print(link)\n",
    "        except:\n",
    "            link = \"NULL\"\n",
    "        try:\n",
    "            subheading = wait.until(EC.presence_of_element_located((By.XPATH, subheading_xpath))).text\n",
    "            print(subheading)\n",
    "        except:\n",
    "            subheading = \"NULL\"\n",
    "        try:\n",
    "            experience = wait.until(EC.presence_of_element_located((By.XPATH, experience_xpath))).text\n",
    "            print(experience)\n",
    "        except:\n",
    "            experience = \"NULL\"\n",
    "        try:\n",
    "            location = wait.until(EC.presence_of_element_located((By.XPATH, location_xpath))).text\n",
    "            print(location)\n",
    "        except:\n",
    "            location = \"NULL\"\n",
    "        try:\n",
    "            salary = wait.until(EC.presence_of_element_located((By.XPATH, salary_xpath))).text\n",
    "            print(salary)\n",
    "        except:\n",
    "            salary = \"Not Disclosed\"'''\n",
    "       \n",
    "        \n",
    "    # Writing all the Scrapped data into CSV file.\n",
    "    #csv_writer.writerow([heading, subheading, link, experience, salary, location])\n",
    "    csv_writer.writerow([heading])\n",
    "\n",
    "    if i >= count:\n",
    "        break\n",
    "\n",
    "wait.until(EC.element_to_be_clickable((By.XPATH, '//*[text() = \"Next\"]'))).click()\n",
    "new_index = 1\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa606ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ravi Suresh Madduri - Assistant General Manager - HR\n",
      "linkedin.com\n",
      "https://in.linkedin.com › ravi-suresh-madduri-97927932\n",
      "https://in.linkedin.com/in/ravi-suresh-madduri-97927932\n",
      "Talent Acquisition\n",
      "Aurobindo Pharma\n",
      "Assistant General Manager - HR\n",
      "Greater Hyderabad Area\n",
      "--------------------------- 1 ----------------------------------\n",
      "Harkara Susmitha - AUROBINDO PHARMA LTD\n",
      "linkedin.com\n",
      "https://in.linkedin.com › harkara-susmitha-75816976\n",
      "https://in.linkedin.com/in/harkara-susmitha-75816976\n",
      "Manager\n",
      "Talent Management-Aurobindo Pharma Limited Research Center. AUROBINDO PHARMA LTD ... Assistant Manager ... Talent Acquisition at AUROBINDO PHARMA LTD.\n",
      "--------------------------- 2 ----------------------------------\n",
      "praveen pulluri - Assistant Manager at Aurobindo Pharma\n",
      "linkedin.com\n",
      "https://in.linkedin.com › praveen-pulluri-121216109\n",
      "https://in.linkedin.com/in/praveen-pulluri-121216109\n",
      "Manager\n",
      "AUROBINDO PHARMA LTD\n",
      "Assistant Manager International Business Development\n",
      "Hyderabad, Telangana, India\n",
      "--------------------------- 3 ----------------------------------\n",
      "Sivaprasad Vugrapali - Assistant Manager- HR\n",
      "linkedin.com\n",
      "https://in.linkedin.com › ...\n",
      "https://in.linkedin.com/in/sivaprasad-vugrapali-7b151354\n",
      "Talent Acquisition\n",
      "Eugia Pharma Specialties Ltd ( Aurobindo Group)\n",
      "Assistant Manager- HR\n",
      "Hyderabad, Telangana, India\n",
      "--------------------------- 4 ----------------------------------\n",
      "Deepti Thakur Kshatri - AUROBINDO PHARMA LTD\n",
      "linkedin.com\n",
      "https://in.linkedin.com › ...\n",
      "https://in.linkedin.com/in/deepti-thakur-kshatri-75b45b1b7\n",
      "Talent Acquisition\n",
      "AUROBINDO PHARMA LTD\n",
      "Assistant Manager\n",
      "Hyderabad, Telangana, India\n",
      "--------------------------- 5 ----------------------------------\n",
      "Kannan. N - Assistant Manager - AUROBINDO PHARMA LTD\n",
      "linkedin.com\n",
      "https://in.linkedin.com › ...\n",
      "https://in.linkedin.com/in/kannan-n-93ba124b?trk=public_profile_samename-profile_profile-result-card_result-card_full-click\n",
      "AUROBINDO PHARMA LTD\n",
      "AUROBINDO PHARMA LTD\n",
      "Assistant Manager\n",
      "Tamil Nadu, India\n",
      "--------------------------- 6 ----------------------------------\n",
      "Chenna Balajee - AUROBINDO PHARMA LTD\n",
      "linkedin.com\n",
      "https://in.linkedin.com › ...\n",
      "https://in.linkedin.com/in/chenna-balajee-255ab2227\n",
      "Manager\n",
      "AUROBINDO PHARMA LTD\n",
      "Assistant Manager Technology transfer\n",
      "Visakhapatnam, Andhra Pradesh, India\n",
      "--------------------------- 7 ----------------------------------\n",
      "Sankara Seetaramarao Rachiraju - Assistant General ...\n",
      "linkedin.com\n",
      "https://in.linkedin.com › sankara-seetaramarao-rachiraju-...\n",
      "https://in.linkedin.com/in/sankara-seetaramarao-rachiraju-602799118?trk=public_profile_browsemap\n",
      "Manager\n",
      "AUROBINDO PHARMA LTD\n",
      "Assistant General Manager-Human Resources\n",
      "Hyderabad, Telangana, India\n",
      "--------------------------- 8 ----------------------------------\n",
      "Swathi Rayala - AUROBINDO PHARMA LTD\n",
      "linkedin.com\n",
      "https://in.linkedin.com › ...\n",
      "https://in.linkedin.com/in/swathi-rayala-94918a254\n",
      "AUROBINDO PHARMA LTD\n",
      "AUROBINDO PHARMA LTD\n",
      "Assistant Manager\n",
      "Hyderabad, Telangana, India\n",
      "--------------------------- 9 ----------------------------------\n",
      "Basant Sahoo - AUROBINDO PHARMA LTD\n",
      "linkedin.com\n",
      "https://in.linkedin.com › ...\n",
      "https://in.linkedin.com/in/basant-sahoo-b379b725a\n",
      "Manager\n",
      "AUROBINDO PHARMA LTD\n",
      "Assistant Manager\n",
      "Hyderabad, Telangana, India\n",
      "--------------------------- 10 ----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Install selenium using command \" pip install selenium \"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Update the URL of Naukri Page! ( Make Sure that the page link which you're putting must be a job listing page and it must have Next page buttons. )\n",
    "driver.get(\"https://www.google.com/search?q=site%3Alinkedin.com%2Fin+AND+%22Aurobindo+Pharma+Ltd%22+AND+%22Talent+Acquisition%22+AND+intitle%3AAssistant+manager+-+Talent+Acquisition%C2%A0&rlz=1C1GCEA_enIN1021IN1021&sxsrf=AB5stBhIShoBuMODt0_aGoJ-MlqvoHsULQ%3A1688467700957&ei=9PijZMr6OcKZseMP1t6JyAM&ved=0ahUKEwjKxJ6s8PT_AhXCTGwGHVZvAjkQ4dUDCA8&uact=5&oq=site%3Alinkedin.com%2Fin+AND+%22Aurobindo+Pharma+Ltd%22+AND+%22Talent+Acquisition%22+AND+intitle%3AAssistant+manager+-+Talent+Acquisition%C2%A0&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAFAAWABgAGgAcAB4AIABAIgBAJIBAJgBAKABAqABAQ&sclient=gws-wiz-serp\")\n",
    "\n",
    "count = 10  # Update the Number of Vacancy count you want to scrape.\n",
    "\n",
    "index, new_index, i = '0', 1, 0  # This the the index variable of the elements from which data will be Scraped\n",
    "# Xpaths of the various element from which data will be scraped.\n",
    "profile_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/div/div/div/a'\n",
    "link_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/div/div/div/a'\n",
    "designation1_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/div/div[2]/div/span/em[2]'\n",
    "designation2_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/div/div[2]/div/span[5]'\n",
    "designation3_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/div/div[2]/div/span[3]'\n",
    "company_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/div/div/div/div/span[5]'\n",
    "location_xpath = '(//*[@class=\"MjjYud\"])['+index+']/div/div/div[2]/div/span[1]'\n",
    "\n",
    "csv_file = open('Aurobindo4.csv', 'a', encoding=\"utf-8\", newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "# Writing the Heading of CSV file.\n",
    "csv_writer.writerow(['Name', 'URL', 'Designation2', 'Designation1', 'Company', 'Designation3','Locations'])\n",
    "\n",
    "while i < count:\n",
    "\n",
    "    for j in range(20):\n",
    "        # Here we're replacing the Old index count of Xpath with New Index count.\n",
    "        temp_index = str(new_index).zfill(2)  # Zfill(2) is used to put zeros to the left of any digit till 2 decimal places.\n",
    "        profile_xpath = profile_xpath.replace(index, temp_index)\n",
    "        link_xpath = link_xpath.replace(index, temp_index)\n",
    "        designation1_xpath = designation1_xpath.replace(index, temp_index)\n",
    "        designation2_xpath = designation2_xpath.replace(index, temp_index)\n",
    "        designation3_xpath = designation3_xpath.replace(index, temp_index)\n",
    "        company_xpath = company_xpath.replace(index, temp_index)\n",
    "        location_xpath = location_xpath.replace(index, temp_index)\n",
    "        index = str(new_index).zfill(2)\n",
    "        try:\n",
    "            # Capturing the Heading from webpage and storing that into Heading variable.\n",
    "            profile = wait.until(EC.presence_of_element_located((By.XPATH, profile_xpath))).text\n",
    "            print(profile)\n",
    "        except:\n",
    "            profile = \"NULL\"\n",
    "        try:\n",
    "            link = wait.until(EC.presence_of_element_located((By.XPATH, link_xpath))).get_attribute('href')\n",
    "            print(link)\n",
    "        except:\n",
    "            link = \"NULL\"\n",
    "        try:\n",
    "            designation1 = wait.until(EC.presence_of_element_located((By.XPATH, designation1_xpath))).text\n",
    "            print(designation1)\n",
    "        except:\n",
    "            designation1 = \"NULL\"\n",
    "        try:\n",
    "            designation2 = wait.until(EC.presence_of_element_located((By.XPATH, designation2_xpath))).text\n",
    "            print(designation2)\n",
    "        except:\n",
    "            designation2 = \"NULL\"\n",
    "        try:\n",
    "            designation3 = wait.until(EC.presence_of_element_located((By.XPATH, designation3_xpath))).text\n",
    "            print(designation3)\n",
    "        except:\n",
    "            designation3 = \"NULL\"\n",
    "        try:\n",
    "            location = wait.until(EC.presence_of_element_located((By.XPATH, location_xpath))).text\n",
    "            print(location)\n",
    "        except:\n",
    "            location = \"NULL\"\n",
    "        try:\n",
    "            company = wait.until(EC.presence_of_element_located((By.XPATH, company_xpath))).text\n",
    "            print(company)\n",
    "        except:\n",
    "            company = \"NULL\"\n",
    "        new_index += 1\n",
    "        i += 1\n",
    "        print(\"--------------------------- \"+str(i)+\" ----------------------------------\")\n",
    "        # Writing all the Scrapped data into CSV file.\n",
    "        csv_writer.writerow([profile, link, company, designation1, designation2, designation3, location])\n",
    "        if i >= count:\n",
    "            break\n",
    "    if i >= count:\n",
    "        break\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//*[text() = \"Next\"]'))).click()\n",
    "    new_index = 1\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675acbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
